Depression Detection on Textual Data Using GPT-Neo with Low-Rank Adaptation (LoRA) for Parameter Efficient Fine Tuning (PEFT)

This project involves the detection of depression in textual data, utilizing the GPT-Neo model. By employing Low-Rank Adaptation (LoRA) for Parameter Efficient Fine Tuning (PEFT), we optimize the performance and efficiency of the model. The dataset used comprises a collection of 7,500 real-life Reddit posts, providing a rich and diverse set of textual data for training and evaluation.
